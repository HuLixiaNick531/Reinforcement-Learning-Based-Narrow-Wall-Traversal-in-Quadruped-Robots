--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   scripts/reinforcement_learning/rsl_rl/train_debug.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc
	deleted:    source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/agents/cusrl_ppo_cfg.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/observations.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/observations.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/unitree_go2_rough/2025-10-31_11-45-57/
	logs/rsl_rl/unitree_go2_rough/2025-10-31_14-29-38/
	outputs/2025-10-31/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/scripts/reinforcement_learning/rsl_rl/train_debug.py b/scripts/reinforcement_learning/rsl_rl/train_debug.py
index ac539e5..03beb17 100644
--- a/scripts/reinforcement_learning/rsl_rl/train_debug.py
+++ b/scripts/reinforcement_learning/rsl_rl/train_debug.py
@@ -29,7 +29,7 @@ sys.path.insert(0, ROOT)
 sys.argv = [
     "train.py",
     "--task=Isaac-Traverse-Walls-Unitree-Go2-v0",
-    # "--headless",
+    "--headless",
     "--num_envs=1024",
     "--max_iterations=10000",
 ]
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc
index a76e956..aaa08c2 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/agents/cusrl_ppo_cfg.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/agents/cusrl_ppo_cfg.py
deleted file mode 100644
index aa93a6a..0000000
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/agents/cusrl_ppo_cfg.py
+++ /dev/null
@@ -1,50 +0,0 @@
-# Copyright (c) 2024-2025 Ziqi Fan
-# SPDX-License-Identifier: Apache-2.0
-
-import cusrl
-from cusrl.environment.isaaclab import TrainerCfg
-
-from isaaclab.utils import configclass
-
-
-@configclass
-class UnitreeGo2RoughTrainerCfg(TrainerCfg):
-    max_iterations = 20000
-    save_interval = 100
-    experiment_name = "unitree_go2_rough"
-    agent_factory = cusrl.ActorCritic.Factory(
-        num_steps_per_update=24,
-        actor_factory=cusrl.Actor.Factory(
-            backbone_factory=cusrl.Mlp.Factory(
-                hidden_dims=[512, 256, 128], activation_fn="ELU", ends_with_activation=True
-            ),
-            distribution_factory=cusrl.NormalDist.Factory(),
-        ),
-        critic_factory=cusrl.Value.Factory(
-            backbone_factory=cusrl.Mlp.Factory(
-                hidden_dims=[512, 256, 128], activation_fn="ELU", ends_with_activation=True
-            ),
-        ),
-        optimizer_factory=cusrl.OptimizerFactory("AdamW", defaults={"lr": 1.0e-3}),
-        sampler=cusrl.AutoMiniBatchSampler(num_epochs=5, num_mini_batches=4),
-        hooks=[
-            cusrl.hook.ValueComputation(),
-            cusrl.hook.GeneralizedAdvantageEstimation(gamma=0.99, lamda=0.95),
-            cusrl.hook.AdvantageNormalization(),
-            cusrl.hook.ValueLoss(),
-            cusrl.hook.OnPolicyPreparation(),
-            cusrl.hook.PpoSurrogateLoss(),
-            cusrl.hook.EntropyLoss(weight=0.008),
-            cusrl.hook.GradientClipping(max_grad_norm=1.0),
-            cusrl.hook.OnPolicyStatistics(sampler=cusrl.AutoMiniBatchSampler()),
-            cusrl.hook.AdaptiveLRSchedule(desired_kl_divergence=0.01),
-        ],
-    )
-
-
-@configclass
-class UnitreeGo2FlatTrainerCfg(UnitreeGo2RoughTrainerCfg):
-    def __post_init__(self):
-        super().__post_init__()
-        self.max_iterations = 5000
-        self.experiment_name = "unitree_go2_flat"
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/observations.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/observations.cpython-311.pyc
index 9776edb..149d554 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/observations.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/observations.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/observations.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/observations.py
index 1c9dcf7..0988637 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/observations.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/observations.py
@@ -31,7 +31,7 @@ class ExtremeTraverseObservations(ManagerTermBase):
         super().__init__(cfg, env)
         self.contact_sensor: ContactSensor = env.scene.sensors['contact_forces']
         self.ray_sensor: RayCaster = env.scene.sensors['height_scanner']
-        self.traverse_event: TraverseEvent =  env.traverse_manager.get_term(cfg.params["traverse_name"])
+        self.traverse_event: TraverseEvent = env.traverse_manager.get_term(cfg.params["traverse_name"])
         self.asset: Articulation = env.scene[cfg.params["asset_cfg"].name]
         self.sensor_cfg = cfg.params["sensor_cfg"]
         self.asset_cfg = cfg.params["asset_cfg"]
@@ -139,6 +139,105 @@ class ExtremeTraverseObservations(ManagerTermBase):
         return torch.clip(self.ray_sensor.data.pos_w[:, 2].unsqueeze(1) - self.ray_sensor.data.ray_hits_w[..., 2] - 0.3, -1, 1).to(self.device)
 
 
+class TraversePolicyObservations(ManagerTermBase):
+    """Policy (Actor) observations for partially observable RL."""
+
+    def __init__(self, cfg: ObservationTermCfg, env: TraverseManagerBasedRLEnv):
+        super().__init__(cfg, env)
+        self.contact_sensor: ContactSensor = env.scene.sensors['contact_forces']
+        self.ray_sensor: RayCaster = env.scene.sensors['height_scanner']
+        self.traverse_event: TraverseEvent = env.traverse_manager.get_term(cfg.params["traverse_name"])
+        self.asset: Articulation = env.scene[cfg.params["asset_cfg"].name]
+        self.sensor_cfg = cfg.params["sensor_cfg"]
+        self.asset_cfg = cfg.params["asset_cfg"]
+        self.history_length = cfg.params['history_length']
+        self._obs_history_buffer = torch.zeros(self.num_envs, self.history_length, 3 + 2 + 3 + 4 + 36 + 5, device=self.device)
+        self.delta_yaw = torch.zeros(self.num_envs, device=self.device)
+        self.delta_next_yaw = torch.zeros(self.num_envs, device=self.device)
+        self.measured_heights = torch.zeros(self.num_envs, 132, device=self.device)
+        self.env = env
+
+    def reset(self, env_ids: Sequence[int] | None = None) -> None:
+        self._obs_history_buffer[env_ids, :, :] = 0. 
+
+    def __call__(
+        self,
+        env: TraverseManagerBasedRLEnv,        
+        asset_cfg: SceneEntityCfg,
+        sensor_cfg: SceneEntityCfg,
+        traverse_name: str,
+        history_length: int,
+        ) -> torch.Tensor:
+        
+        terrain_names = self.traverse_event.env_per_terrain_name
+        env_idx_tensor = torch.tensor((terrain_names != 'traverse_flat'), dtype=torch.bool, device=self.device)
+        invert_env_idx_tensor = torch.tensor((terrain_names == 'traverse_flat'), dtype=torch.bool, device=self.device)
+
+        # --- base orientation from IMU ---
+        roll, pitch, yaw = euler_xyz_from_quat(self.asset.data.root_quat_w)
+        imu_obs = torch.stack((wrap_to_pi(roll), wrap_to_pi(pitch)), dim=1).to(self.device)
+
+        # --- update every 5 steps ---
+        if env.common_step_counter % 5 == 0:
+            self.delta_yaw = self.traverse_event.target_yaw - wrap_to_pi(yaw)
+            self.delta_next_yaw = self.traverse_event.next_target_yaw - wrap_to_pi(yaw)
+            self.measured_heights = self._get_heights()
+
+        commands = env.command_manager.get_command('base_velocity')
+
+        obs_buf = torch.cat((
+            self.asset.data.root_ang_vel_b * 0.25,    # 3
+            imu_obs,                                  # 2
+            0*self.delta_yaw[:, None],                # 1  ← 保留占位
+            self.delta_yaw[:, None],                  # 1
+            self.delta_next_yaw[:, None],             # 1
+            0*commands[:, 0:2],                       # 2  ← 保留占位
+            commands[:, 0:1],                         # 1
+            env_idx_tensor,                           # 1
+            invert_env_idx_tensor,                    # 1
+            self.asset.data.joint_pos - self.asset.data.default_joint_pos,  # 12
+            self.asset.data.joint_vel * 0.05,         # 12
+            env.action_manager.get_term('joint_pos').action_history_buf[:, -1],  # 12
+            self._get_contact_fill(),                 # 4
+        ), dim=-1)
+
+        # 拼接最终 observation （policy 不再使用 priv info）
+        observations = torch.cat([
+            obs_buf,                          # proprioceptive
+            self.measured_heights,            # exteroceptive height scan
+            self._obs_history_buffer.view(self.num_envs, -1)  # temporal
+        ], dim=-1)
+
+        # --- 更新历史缓冲区 ---
+        obs_buf[:, 6:8] = 0  # reset yaw deltas for history storage consistency
+        self._obs_history_buffer = torch.where(
+            (env.episode_length_buf <= 1)[:, None, None], 
+            torch.stack([obs_buf] * self.history_length, dim=1),
+            torch.cat([
+                self._obs_history_buffer[:, 1:],
+                obs_buf.unsqueeze(1)
+            ], dim=1)
+        )
+
+        return observations
+
+    def _get_contact_fill(self):
+        contact_forces = self.contact_sensor.data.net_forces_w_history[:, 0, self.sensor_cfg.body_ids]  # (N, 4, 3)
+        contact = torch.norm(contact_forces, dim=-1) > 2.
+        previous_contact_forces = self.contact_sensor.data.net_forces_w_history[:, -1, self.sensor_cfg.body_ids]
+        last_contacts = torch.norm(previous_contact_forces, dim=-1) > 2.
+        contact_filt = torch.logical_or(contact, last_contacts)
+        return (contact_filt.float() - 0.5).to(self.device)
+
+    def _get_heights(self):
+        """Height field sampling."""
+        return torch.clip(
+            self.ray_sensor.data.pos_w[:, 2].unsqueeze(1)
+            - self.ray_sensor.data.ray_hits_w[..., 2]
+            - 0.3,
+            -1, 1
+        ).to(self.device)
+
 class image_features(ManagerTermBase):  
     def __init__(self, cfg: ObservationTermCfg, env: TraverseManagerBasedRLEnv):
         super().__init__(cfg, env)
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
index c83a69a..1d9b444 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
@@ -166,7 +166,7 @@ class ObservationsCfg:
         """Observations for policy group."""
         # observation terms (order preserved)
         extreme_traverse_observations = ObsTerm(
-            func=observations.ExtremeTraverseObservations,
+            func=observations.TraversePolicyObservations,
             params={            
             "asset_cfg":SceneEntityCfg("robot"),
             "sensor_cfg":SceneEntityCfg("contact_forces", body_names=".*_foot"),
@@ -177,22 +177,22 @@ class ObservationsCfg:
         )
     policy: PolicyCfg = PolicyCfg()
 
-    # @configclass
-    # class CriticCfg(ObsGroup):
-    #     """Observations for policy group."""
-    #     # observation terms (order preserved)
-    #     extreme_traverse_observations = ObsTerm(
-    #         func=observations.ExtremeTraverseObservations,
-    #         params={            
-    #         "asset_cfg":SceneEntityCfg("robot"),
-    #         "sensor_cfg":SceneEntityCfg("contact_forces", body_names=".*_foot"),
-    #         "traverse_name":'base_traverse',
-    #         "history_length": 10
-    #         },
-    #         clip= (-100,100)
-    #     )
-    # # observation groups
-    # critic: CriticCfg = CriticCfg()
+    @configclass
+    class CriticCfg(ObsGroup):
+        """Observations for policy group."""
+        # observation terms (order preserved)
+        extreme_traverse_observations = ObsTerm(
+            func=observations.ExtremeTraverseObservations,
+            params={            
+            "asset_cfg":SceneEntityCfg("robot"),
+            "sensor_cfg":SceneEntityCfg("contact_forces", body_names=".*_foot"),
+            "traverse_name":'base_traverse',
+            "history_length": 10
+            },
+            clip= (-100,100)
+        )
+    # observation groups
+    critic: CriticCfg = CriticCfg()
 
 
 @configclass