# Reinforcement Learning-Based Narrow Wall Traversal in Quadruped Robots

This repository is based on **Isaac Lab** and implements a **reinforcement learning (RL)** framework for training a quadruped robot (Unitree Go2) to traverse narrow corridors safely and efficiently.

---

## ğŸ§  Project Overview

The project aims to enable **autonomous narrow-wall traversal** using **reinforcement learning** techniques.  
It integrates **Isaac Sim**, **Isaac Lab**, and **RSL-RL** for parallel simulation and policy optimization.

---

## ğŸ“¦ Environment Setup

### 1. Clone Repository
```bash
git clone https://github.com/HuLixiaNick531/Reinforcement-Learning-Based-Narrow-Wall-Traversal-in-Quadruped-Robots.git
cd Reinforcement-Learning-Based-Narrow-Wall-Traversal-in-Quadruped-Robots
```

### 2. Install Dependencies
Make sure you have **Isaac Lab** and **RSL-RL** installed properly.  
Recommended environment:
- Python â‰¥ 3.10  
- NVIDIA GPU (for parallel simulation)
- Isaac Sim 4.x
- Isaac Lab (latest release)

Example (inside Isaac Lab environment):
```bash
conda activate env_isaaclab
python -m pip install -e source/robot_lab
```
---

## ğŸš€ Training Command

To start training the quadruped agent:

```bash
python scripts/reinforcement_learning/rsl_rl/train.py     --task RobotLab-Isaac-Velocity-Narrow-Unitree-Go2-v0     --num_envs=400
```

This launches RSL-RL with **400 parallel environments**, using the `Unitree Go2` robot model to learn a velocity-based navigation policy.

---


## ğŸ§© Repository Structure

The project follows the Isaac Lab extension layout, with modularized folders for robot assets, tasks, and training logic.

```
.
â”œâ”€â”€ config/                                # Isaac Lab extension configuration
â”‚   â””â”€â”€ extension.toml
â”‚
â”œâ”€â”€ data/                                  # Robot model and mesh resources
â”‚   â””â”€â”€ Robots/
â”‚       â””â”€â”€ unitree/
â”‚           â””â”€â”€ go2_description/
â”‚               â”œâ”€â”€ meshes/                # Mesh files for Go2 robot (DAE format)
â”‚               â”‚   â”œâ”€â”€ base.dae
â”‚               â”‚   â”œâ”€â”€ calf.dae
â”‚               â”‚   â”œâ”€â”€ foot.dae
â”‚               â”‚   â””â”€â”€ ...
â”‚               â””â”€â”€ urdf/
â”‚                   â””â”€â”€ go2_description.urdf
â”‚
â”œâ”€â”€ pyproject.toml                         # Project metadata and build config
â”œâ”€â”€ setup.py                               # Setup script for installation
â”‚
â”œâ”€â”€ robot_lab/                             # Core Isaac Lab extension source
â”‚   â”œâ”€â”€ assets/                            # Robot asset definitions
â”‚   â”‚   â”œâ”€â”€ backup_origin/
â”‚   â”‚   â”‚   â””â”€â”€ unitree.py
â”‚   â”‚   â””â”€â”€ unitree.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                             # Task and environment definitions
â”‚   â”‚   â”œâ”€â”€ direct/                        # Direct control mode
â”‚   â”‚   â””â”€â”€ manager_based/                 # Manager-based task definition
â”‚   â”‚       â””â”€â”€ locomotion/
â”‚   â”‚           â””â”€â”€ velocity/
â”‚   â”‚               â”œâ”€â”€ config/            # Configuration for quadruped tasks
â”‚   â”‚               â”‚   â””â”€â”€ quadruped/unitree_go2/
â”‚   â”‚               â”œâ”€â”€ mdp/               # MDP components (commands, rewards, etc.)
â”‚   â”‚               â”‚   â”œâ”€â”€ commands.py
â”‚   â”‚               â”‚   â”œâ”€â”€ rewards.py
â”‚   â”‚               â”‚   â””â”€â”€ curriculums.py
â”‚   â”‚               â””â”€â”€ velocity_env_cfg.py
â”‚   â”‚
â”‚   â””â”€â”€ ui_extension_example.py            # Optional Isaac Lab UI extension example
â”‚
â”œâ”€â”€ robot_lab.egg-info/                    # Build artifacts (auto-generated)
â”‚   â”œâ”€â”€ PKG-INFO
â”‚   â””â”€â”€ SOURCES.txt
â”‚
â””â”€â”€ scripts/
    â””â”€â”€ reinforcement_learning/
        â””â”€â”€ rsl_rl/
            â”œâ”€â”€ train.py                   # Main training script (entry point)
            â”œâ”€â”€ configs/                   # PPO and task hyperparameters
            â””â”€â”€ utils/                     # (Optional) helper tools
```



---

### ğŸ” Key Components

| Folder | Description |
|--------|--------------|
| `data/Robots/unitree/` | Stores robot models, meshes, and URDFs. |
| `robot_lab/assets/` | Python definitions for robot assets used in simulation. |
| `robot_lab/tasks/manager_based/` | Main RL environments built on Isaac Lab's task manager. |
| `robot_lab/tasks/manager_based/locomotion/velocity/` | Contains velocity-control environments and curriculum logic. |
| `scripts/reinforcement_learning/rsl_rl/train.py` | Main script to launch reinforcement learning training. |


---

## ğŸ“Š Results & Visualization


---

## ğŸ™ Acknowledgements

This project draws inspiration and partial structure from the excellent open-source repository:

- [**fan-ziqi/robot_lab**](https://github.com/fan-ziqi/robot_lab)

We sincerely thank the original authors for their open-source contributions.  
Their work on **Isaac Lab-based robot simulation and reinforcement learning framework** provided valuable reference and a solid foundation for this projectâ€™s development.

