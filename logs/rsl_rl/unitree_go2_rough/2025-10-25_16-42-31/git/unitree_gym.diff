--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   scripts/reinforcement_learning/rsl_rl/train_debug.py
	modified:   source/unitree_gym/unitree_gym/assets/__pycache__/unitree.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__init__.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/__init__.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/rough_env_cfg.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/flat_env_cfg.py
	deleted:    source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/rough_env_cfg.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/rewards.cpython-311.pyc
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/rewards.py
	modified:   source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/
	outputs/
	source/unitree_gym/unitree_gym/assets/__init__.py
	source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/traverse_env_cfg.cpython-311.pyc
	source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/traverse_env_cfg.py

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/scripts/reinforcement_learning/rsl_rl/train_debug.py b/scripts/reinforcement_learning/rsl_rl/train_debug.py
index b94a8e4..ba0607b 100644
--- a/scripts/reinforcement_learning/rsl_rl/train_debug.py
+++ b/scripts/reinforcement_learning/rsl_rl/train_debug.py
@@ -28,9 +28,9 @@ sys.path.insert(0, ROOT)
 
 sys.argv = [
     "train.py",
-    "--task=RobotLab-Isaac-Velocity-Flat-Unitree-Go2-v0",
-    "--headless",
-    "--num_envs=64",
+    "--task=Isaac-Traverse-Walls-Unitree-Go2-v0",
+    # "--headless",
+    "--num_envs=32",
     "--max_iterations=10000",
 ]
 
diff --git a/source/unitree_gym/unitree_gym/assets/__pycache__/unitree.cpython-311.pyc b/source/unitree_gym/unitree_gym/assets/__pycache__/unitree.cpython-311.pyc
index 9d44a1c..7e758c7 100644
Binary files a/source/unitree_gym/unitree_gym/assets/__pycache__/unitree.cpython-311.pyc and b/source/unitree_gym/unitree_gym/assets/__pycache__/unitree.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc
index 78d1c01..bf4dfb7 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/__pycache__/velocity_env_cfg.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__init__.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__init__.py
index 5181788..f68bf37 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__init__.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__init__.py
@@ -9,24 +9,25 @@ from . import agents
 # Register Gym environments.
 ##
 
+
 gym.register(
-    id="RobotLab-Isaac-Velocity-Flat-Unitree-Go2-v0",
-    entry_point="unitree_gym.tasks.manager_based.locomotion.velocity.envs.unitree_go2_env:UnitreeGo2RoughEnv",
+    id="Isaac-Traverse-Walls-Unitree-Go2-v0",
+    entry_point="isaaclab.envs:ManagerBasedRLEnv",
     disable_env_checker=True,
     kwargs={
-        "env_cfg_entry_point": f"{__name__}.flat_env_cfg:UnitreeGo2FlatEnvCfg",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2FlatPPORunnerCfg",
-        "cusrl_cfg_entry_point": f"{agents.__name__}.cusrl_ppo_cfg:UnitreeGo2FlatTrainerCfg",
+        "env_cfg_entry_point": f"{__name__}.traverse_env_cfg:UnitreeGo2TraverseEnvCfg",
+        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2RoughPPORunnerCfg",
+        "cusrl_cfg_entry_point": f"{agents.__name__}.cusrl_ppo_cfg:UnitreeGo2RoughTrainerCfg",
     },
 )
 
 gym.register(
-    id="RobotLab-Isaac-Velocity-Rough-Unitree-Go2-v0",
+    id="RobotLab-Isaac-Velocity-Flat-Unitree-Go2-v0",
     entry_point="isaaclab.envs:ManagerBasedRLEnv",
     disable_env_checker=True,
     kwargs={
-        "env_cfg_entry_point": f"{__name__}.rough_env_cfg:UnitreeGo2RoughEnvCfg",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2RoughPPORunnerCfg",
-        "cusrl_cfg_entry_point": f"{agents.__name__}.cusrl_ppo_cfg:UnitreeGo2RoughTrainerCfg",
+        "env_cfg_entry_point": f"{__name__}.flat_env_cfg:UnitreeGo2FlatEnvCfg",
+        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:UnitreeGo2FlatPPORunnerCfg",
+        "cusrl_cfg_entry_point": f"{agents.__name__}.cusrl_ppo_cfg:UnitreeGo2FlatTrainerCfg",
     },
 )
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/__init__.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/__init__.cpython-311.pyc
index 1f5946e..80a950d 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/__init__.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/__init__.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/rough_env_cfg.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/rough_env_cfg.cpython-311.pyc
index bf02cd7..1591af2 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/rough_env_cfg.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/__pycache__/rough_env_cfg.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/flat_env_cfg.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/flat_env_cfg.py
index f6dbb2a..47c53d3 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/flat_env_cfg.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/flat_env_cfg.py
@@ -3,11 +3,11 @@
 
 from isaaclab.utils import configclass
 
-from .rough_env_cfg import UnitreeGo2RoughEnvCfg
+from .rough_env_cfg import UnitreeGo2TraverseEnvCfg
 
 
 @configclass
-class UnitreeGo2FlatEnvCfg(UnitreeGo2RoughEnvCfg):
+class UnitreeGo2FlatEnvCfg(UnitreeGo2TraverseEnvCfg):
     def __post_init__(self):
         # post init of parent
         super().__post_init__()
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/rough_env_cfg.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/rough_env_cfg.py
deleted file mode 100644
index bb22223..0000000
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/config/quadruped/unitree_go2/rough_env_cfg.py
+++ /dev/null
@@ -1,166 +0,0 @@
-# Copyright (c) 2024-2025 Ziqi Fan
-# SPDX-License-Identifier: Apache-2.0
-
-from isaaclab.utils import configclass
-
-from unitree_gym.tasks.manager_based.locomotion.velocity.velocity_env_cfg import LocomotionVelocityRoughEnvCfg_Go2
-
-##
-# Pre-defined configs
-##
-# # use cloud assets
-# from isaaclab_assets.robots.unitree import UNITREE_GO2_CFG  # isort: skip
-# use local assets
-from unitree_gym.assets.unitree import UNITREE_GO2_CFG  # isort: skip
-
-
-@configclass
-class UnitreeGo2RoughEnvCfg(LocomotionVelocityRoughEnvCfg_Go2):
-    base_link_name = "base"
-    foot_link_name = ".*_foot"
-    # fmt: off
-    joint_names = [
-        "FR_hip_joint", "FR_thigh_joint", "FR_calf_joint",
-        "FL_hip_joint", "FL_thigh_joint", "FL_calf_joint",
-        "RR_hip_joint", "RR_thigh_joint", "RR_calf_joint",
-        "RL_hip_joint", "RL_thigh_joint", "RL_calf_joint",
-    ]
-    # fmt: on
-
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # ------------------------------Sence------------------------------
-        self.scene.robot = UNITREE_GO2_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-        self.scene.height_scanner.prim_path = "{ENV_REGEX_NS}/Robot/" + self.base_link_name
-        self.scene.height_scanner_base.prim_path = "{ENV_REGEX_NS}/Robot/" + self.base_link_name
-
-        # ------------------------------Observations------------------------------
-        self.observations.policy.base_lin_vel.scale = 2.0
-        self.observations.policy.base_ang_vel.scale = 0.25
-        self.observations.policy.joint_pos.scale = 1.0
-        self.observations.policy.joint_vel.scale = 0.05
-        self.observations.policy.base_lin_vel = None
-        self.observations.policy.height_scan = None
-        self.observations.policy.joint_pos.params["asset_cfg"].joint_names = self.joint_names
-        self.observations.policy.joint_vel.params["asset_cfg"].joint_names = self.joint_names
-
-        # ------------------------------Actions------------------------------
-        # reduce action scale
-        self.actions.joint_pos.scale = {".*_hip_joint": 0.125, "^(?!.*_hip_joint).*": 0.25}
-        self.actions.joint_pos.clip = {".*": (-100.0, 100.0)}
-        self.actions.joint_pos.joint_names = self.joint_names
-
-        # ------------------------------Events------------------------------
-        self.events.randomize_reset_base.params = {
-            "pose_range": {
-                "x": (-0.5, 0.5),
-                "y": (-0.5, 0.5),
-                "z": (0.0, 0.2),
-                "roll": (-0.31, 0.31),
-                "pitch": (-0.31, 0.31),
-                "yaw": (-3.14, 3.14),
-            },
-            "velocity_range": {
-                "x": (-0.5, 0.5),
-                "y": (-0.5, 0.5),
-                "z": (-0.5, 0.5),
-                "roll": (-0.5, 0.5),
-                "pitch": (-0.5, 0.5),
-                "yaw": (-0.5, 0.5),
-            },
-        }
-        self.events.randomize_rigid_body_mass_base.params["asset_cfg"].body_names = [self.base_link_name]
-        self.events.randomize_rigid_body_mass_others.params["asset_cfg"].body_names = [self.foot_link_name]
-        self.events.randomize_com_positions.params["asset_cfg"].body_names = [self.base_link_name]
-        self.events.randomize_apply_external_force_torque.params["asset_cfg"].body_names = [self.base_link_name]
-
-        # self.events.spawn_walls
-
-        # ------------------------------Rewards------------------------------
-        # General
-        self.rewards.is_terminated.weight = 0
-
-        # Root penalties
-        self.rewards.lin_vel_z_l2.weight = -2.0
-        self.rewards.ang_vel_xy_l2.weight = -0.05
-        self.rewards.flat_orientation_l2.weight = 0
-        self.rewards.base_height_l2.weight = 0
-        self.rewards.base_height_l2.params["target_height"] = 0.33
-        self.rewards.base_height_l2.params["asset_cfg"].body_names = [self.base_link_name]
-        self.rewards.body_lin_acc_l2.weight = 0
-        self.rewards.body_lin_acc_l2.params["asset_cfg"].body_names = [self.base_link_name]
-
-        # Joint penalties
-        self.rewards.joint_torques_l2.weight = -2.5e-5
-        self.rewards.joint_vel_l2.weight = 0
-        self.rewards.joint_acc_l2.weight = -2.5e-7
-        # self.rewards.create_joint_deviation_l1_rewterm("joint_deviation_hip_l1", -0.2, [".*_hip_joint"])
-        self.rewards.joint_pos_limits.weight = -5.0
-        self.rewards.joint_vel_limits.weight = 0
-        self.rewards.joint_power.weight = -2e-5
-        self.rewards.stand_still.weight = -2.0
-        self.rewards.joint_pos_penalty.weight = -1.0
-        self.rewards.joint_mirror.weight = -0.05
-        self.rewards.joint_mirror.params["mirror_joints"] = [
-            ["FR_(hip|thigh|calf).*", "RL_(hip|thigh|calf).*"],
-            ["FL_(hip|thigh|calf).*", "RR_(hip|thigh|calf).*"],
-        ]
-
-        # Action penalties
-        self.rewards.action_rate_l2.weight = -0.01
-
-        # Contact sensor
-        self.rewards.undesired_contacts.weight = -1.0
-        self.rewards.undesired_contacts.params["sensor_cfg"].body_names = [f"^(?!.*{self.foot_link_name}).*"]
-        self.rewards.contact_forces.weight = -1.5e-4
-        self.rewards.contact_forces.params["sensor_cfg"].body_names = [self.foot_link_name]
-
-        # Velocity-tracking rewards
-        self.rewards.track_lin_vel_xy_exp.weight = 3.0
-        self.rewards.track_ang_vel_z_exp.weight = 1.5
-
-        # Others
-        self.rewards.feet_air_time.weight = 0.1
-        self.rewards.feet_air_time.params["threshold"] = 0.5
-        self.rewards.feet_air_time.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_air_time_variance.weight = -1.0
-        self.rewards.feet_air_time_variance.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_contact.weight = 0
-        self.rewards.feet_contact.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_contact_without_cmd.weight = 0.1
-        self.rewards.feet_contact_without_cmd.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_stumble.weight = 0
-        self.rewards.feet_stumble.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_slide.weight = -0.1
-        self.rewards.feet_slide.params["sensor_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_slide.params["asset_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_height.weight = 0
-        self.rewards.feet_height.params["target_height"] = 0.05
-        self.rewards.feet_height.params["asset_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_height_body.weight = -5.0
-        self.rewards.feet_height_body.params["target_height"] = -0.2
-        self.rewards.feet_height_body.params["asset_cfg"].body_names = [self.foot_link_name]
-        self.rewards.feet_gait.weight = 0.5
-        self.rewards.feet_gait.params["synced_feet_pair_names"] = (("FL_foot", "RR_foot"), ("FR_foot", "RL_foot"))
-        self.rewards.upward.weight = 1.0
-
-        # If the weight of rewards is 0, set rewards to None
-        if self.__class__.__name__ == "UnitreeGo2RoughEnvCfg":
-            self.disable_zero_weight_rewards()
-
-        # ------------------------------Terminations------------------------------
-        # self.terminations.illegal_contact.params["sensor_cfg"].body_names = [self.base_link_name, ".*_hip"]
-        self.terminations.illegal_contact = None
-
-        # ------------------------------Curriculums------------------------------
-        # self.curriculum.command_levels.params["range_multiplier"] = (0.2, 1.0)
-        self.curriculum.command_levels = None
-        self.curriculum.wall_width_curriculum.params["initial_width"] = 0.6
-        self.curriculum.wall_width_curriculum.params["final_width"] = 0.4
-
-        # ------------------------------Commands------------------------------
-        # self.commands.base_velocity.ranges.lin_vel_x = (-1.0, 1.0)
-        # self.commands.base_velocity.ranges.lin_vel_y = (-0.5, 0.5)
-        # self.commands.base_velocity.ranges.ang_vel_z = (-1.0, 1.0)    
\ No newline at end of file
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/rewards.cpython-311.pyc b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/rewards.cpython-311.pyc
index 4078cf4..611bc42 100644
Binary files a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/rewards.cpython-311.pyc and b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/__pycache__/rewards.cpython-311.pyc differ
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/rewards.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/rewards.py
index b65d4b7..dbffb78 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/rewards.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/mdp/rewards.py
@@ -126,30 +126,6 @@ def joint_pos_penalty(
     return reward
 
 
-def wheel_vel_penalty(
-    env: ManagerBasedRLEnv,
-    sensor_cfg: SceneEntityCfg,
-    command_name: str,
-    velocity_threshold: float,
-    command_threshold: float,
-    asset_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-) -> torch.Tensor:
-    asset: Articulation = env.scene[asset_cfg.name]
-    cmd = torch.linalg.norm(env.command_manager.get_command(command_name), dim=1)
-    body_vel = torch.linalg.norm(asset.data.root_lin_vel_b[:, :2], dim=1)
-    joint_vel = torch.abs(asset.data.joint_vel[:, asset_cfg.joint_ids])
-    contact_sensor: ContactSensor = env.scene.sensors[sensor_cfg.name]
-    in_air = contact_sensor.compute_first_air(env.step_dt)[:, sensor_cfg.body_ids]
-    running_reward = torch.sum(in_air * joint_vel, dim=1)
-    standing_reward = torch.sum(joint_vel, dim=1)
-    reward = torch.where(
-        torch.logical_or(cmd > command_threshold, body_vel > velocity_threshold),
-        running_reward,
-        standing_reward,
-    )
-    return reward
-
-
 class GaitReward(ManagerTermBase):
     """Gait enforcing reward term for quadrupeds.
 
diff --git a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
index a23dc7a..b2ee9c7 100644
--- a/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
+++ b/source/unitree_gym/unitree_gym/tasks/manager_based/locomotion/velocity/velocity_env_cfg.py
@@ -34,7 +34,7 @@ import unitree_gym.tasks.manager_based.locomotion.velocity.mdp as mdp
 # Pre-defined configs
 ##
 from isaaclab.terrains.config.rough import ROUGH_TERRAINS_CFG  # isort: skip
-from unitree_gym.tasks.manager_based.locomotion.velocity.terrains.wall import WALLS_TERRAINS_CFG
+# from unitree_gym.tasks.manager_based.locomotion.velocity.terrains.wall import WALLS_TERRAINS_CFG
 
 
 ##
@@ -42,14 +42,14 @@ from unitree_gym.tasks.manager_based.locomotion.velocity.terrains.wall import WA
 ##
 
 @configclass
-class MySceneCfg_Go2(InteractiveSceneCfg):
+class MySceneGo2Cfg(InteractiveSceneCfg):
     """Configuration for the terrain scene with a legged robot."""
 
     # ground terrain
     terrain = TerrainImporterCfg(
         prim_path="/World/ground",
         terrain_type="generator",
-        terrain_generator=WALLS_TERRAINS_CFG,
+        terrain_generator=ROUGH_TERRAINS_CFG,
         max_init_terrain_level=5,
         collision_group=-1,
         physics_material=sim_utils.RigidBodyMaterialCfg(
@@ -94,27 +94,7 @@ class MySceneCfg_Go2(InteractiveSceneCfg):
             texture_file=f"{ISAAC_NUCLEUS_DIR}/Materials/Textures/Skies/PolyHaven/kloofendal_43d_clear_puresky_4k.hdr",
         ),
     )
-    # wall_left = RigidObjectCfg(
-    #     prim_path="{ENV_REGEX_NS}/WallLeft",
-    #     spawn=sim_utils.CuboidCfg(
-    #         size=(2.0, 0.15, 1.2),  # 长、厚、高
-    #         rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True),
-    #         collision_props=sim_utils.CollisionPropertiesCfg(),
-    #         visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.85, 0.85, 0.85)),
-    #     ),
-    #     # 先给个默认位姿，后面用 reset 事件精确放置
-    #     init_state=RigidObjectCfg.InitialStateCfg(pos=(2.0, 0.2, 0.6)),
-    # )
-    # wall_right = RigidObjectCfg(
-    #     prim_path="{ENV_REGEX_NS}/WallRight",
-    #     spawn=sim_utils.CuboidCfg(
-    #         size=(2.0, 0.15, 1.2),
-    #         rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True),
-    #         collision_props=sim_utils.CollisionPropertiesCfg(),
-    #         visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.85, 0.85, 0.85)),
-    #     ),
-    #     init_state=RigidObjectCfg.InitialStateCfg(pos=(2.0, -0.2, 0.6)),
-    # )
+
 
 ##
 # MDP settings
@@ -480,18 +460,6 @@ class RewardsCfg:
         },
     )
 
-    wheel_vel_penalty = RewTerm(
-        func=mdp.wheel_vel_penalty,
-        weight=0.0,
-        params={
-            "asset_cfg": SceneEntityCfg("robot", joint_names=""),
-            "sensor_cfg": SceneEntityCfg("contact_forces", body_names=""),
-            "command_name": "base_velocity",
-            "velocity_threshold": 0.5,
-            "command_threshold": 0.1,
-        },
-    )
-
     joint_mirror = RewTerm(
         func=mdp.joint_mirror,
         weight=0.0,
@@ -736,61 +704,11 @@ class CurriculumCfg:
 
 
 @configclass
-class LocomotionVelocityRoughEnvCfg(ManagerBasedRLEnvCfg):
-    """Configuration for the locomotion velocity-tracking environment."""
-
-    # Scene settings
-    scene: MySceneCfg = MySceneCfg(num_envs=4096, env_spacing=2.5)
-    # Basic settings
-    observations: ObservationsCfg = ObservationsCfg()
-    actions: ActionsCfg = ActionsCfg()
-    commands: CommandsCfg = CommandsCfg()
-    # MDP settings
-    rewards: RewardsCfg = RewardsCfg()
-    terminations: TerminationsCfg = TerminationsCfg()
-    events: EventCfg = EventCfg()
-    curriculum: CurriculumCfg = CurriculumCfg()
-
-    def __post_init__(self):
-        """Post initialization."""
-        # general settings
-        self.decimation = 4
-        self.episode_length_s = 20.0
-        # simulation settings
-        self.sim.dt = 0.005
-        self.sim.render_interval = self.decimation
-        self.sim.physics_material = self.scene.terrain.physics_material
-        self.sim.physx.gpu_max_rigid_patch_count = 10 * 2**15
-        # update sensor update periods
-        # we tick all the sensors based on the smallest update period (physics update period)
-        if self.scene.height_scanner is not None:
-            self.scene.height_scanner.update_period = self.decimation * self.sim.dt
-        if self.scene.contact_forces is not None:
-            self.scene.contact_forces.update_period = self.sim.dt
-
-        # check if terrain levels curriculum is enabled - if so, enable curriculum for terrain generator
-        # this generates terrains with increasing difficulty and is useful for training
-        if getattr(self.curriculum, "terrain_levels", None) is not None:
-            if self.scene.terrain.terrain_generator is not None:
-                self.scene.terrain.terrain_generator.curriculum = True
-        else:
-            if self.scene.terrain.terrain_generator is not None:
-                self.scene.terrain.terrain_generator.curriculum = False
-
-    def disable_zero_weight_rewards(self):
-        """If the weight of rewards is 0, set rewards to None"""
-        for attr in dir(self.rewards):
-            if not attr.startswith("__"):
-                reward_attr = getattr(self.rewards, attr)
-                if not callable(reward_attr) and reward_attr.weight == 0:
-                    setattr(self.rewards, attr, None)
-
-@configclass
-class LocomotionVelocityRoughEnvCfg_Go2(ManagerBasedRLEnvCfg):
+class LocomotionVelocityGo2EnvCfg(ManagerBasedRLEnvCfg):
     """Configuration for the locomotion velocity-tracking environment."""
 
     # Scene settings
-    scene: MySceneCfg_Go2 = MySceneCfg_Go2(num_envs=4096, env_spacing=6.0)
+    scene: MySceneGo2Cfg = MySceneGo2Cfg(num_envs=4096, env_spacing=6.0)
     # Basic settings
     observations: ObservationsCfg = ObservationsCfg()
     actions: ActionsCfg = ActionsCfg()